<!DOCTYPE HTML PUBLIC "-//W3O//DTD W3 HTML 2.0//EN">
<!--Converted with LaTeX2HTML 95 (Thu Jan 19 1995) by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds -->
<head><script src="https://archive.org/includes/analytics.js?v=cf34f82" type="text/javascript"></script>
<script type="text/javascript">window.addEventListener('DOMContentLoaded',function(){var v=archive_analytics.values;v.service='wb';v.server_name='wwwb-app216.us.archive.org';v.server_ms=543;archive_analytics.send_pageview({});});</script>
<script type="text/javascript" src="https://web.archive.org/_static/js/bundle-playback.js?v=KTqwAcYd" charset="utf-8"></script>
<script type="text/javascript" src="https://web.archive.org/_static/js/wombat.js?v=UHAOicsW" charset="utf-8"></script>
<script type="text/javascript">
  __wm.init("https://web.archive.org/web");
  __wm.wombat("http://www.vhdl.org:80/~wyle/diss/node36.html","19971014211003","https://web.archive.org/","web","/_static/",
	      "876863403");
</script>
<link rel="stylesheet" type="text/css" href="https://web.archive.org/_static/css/banner-styles.css?v=fantwOh2" />
<link rel="stylesheet" type="text/css" href="https://web.archive.org/_static/css/iconochive.css?v=qtvMKcIJ" />
<!-- End Wayback Rewrite JS Include -->

<title> Interpretation of Experiment Results</title>
</head>
<body>
<meta name="description" value=" Interpretation of Experiment Results">
<meta name="keywords" value="diss">
<meta name="resource-type" value="document">
<meta name="distribution" value="global">
<p>
 <br> <hr><a name="tex2html1526" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node37.html"><img align="BOTTOM" alt="next" src="https://web.archive.org/web/19971014211003im_/http://vhdl.org/~wyle/diss/images/next_motif.gif"></a>   <a name="tex2html1524" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node35.html"><img align="BOTTOM" alt="up" src="https://web.archive.org/web/19971014211003im_/http://vhdl.org/~wyle/diss/images/up_motif.gif"></a>   <a name="tex2html1518" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node35.html"><img align="BOTTOM" alt="previous" src="https://web.archive.org/web/19971014211003im_/http://vhdl.org/~wyle/diss/images/previous_motif.gif"></a>   <a name="tex2html1528" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node2.html"><img align="BOTTOM" alt="contents" src="https://web.archive.org/web/19971014211003im_/http://vhdl.org/~wyle/diss/images/contents_motif.gif"></a>   <a name="tex2html1529" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node57.html"><img align="BOTTOM" alt="index" src="https://web.archive.org/web/19971014211003im_/http://vhdl.org/~wyle/diss/images/index_motif.gif"></a>   <br>
<b> Next:</b> <a name="tex2html1527" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node37.html"> Performance Evaluation in </a>
<b>Up:</b> <a name="tex2html1525" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node35.html"> Conclusionand Outlook</a>
<b> Previous:</b> <a name="tex2html1519" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node35.html"> Conclusionand Outlook</a>
<br> <hr> <p>
<h1><a name="SECTION001010000000000000000"> Interpretation of Experiment Results</a></h1>
<p>
In this section, we shall try to elucidate the meaning and implications
of the results presented at the end of the last chapter.  First, we
answer the questions raised in each of the hypotheses and clarify the
implication the answers have for developing an <b>IS</b>.  We also analyse
the computing resources required for these algorithms and conclude with
a dense summary of the trade-offs involved in implementing and applying
the methods to retrieving messages from dynamic document collections
filtered from the Matrix.
<p>
The answer to hypothesis<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node34.html#hsswpsw">1</a> is clearly that full Porter
word reduction is better in our WAN messaging environment than
S-stemming.  These results bear out Julie Lovins' [<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node40.html#Lovi71">Lovi71</a>]
original work indicating that the loss in meaning due to over-reduction
is indeed small, or at least small enough not to adversely affect
retrieval performance.   The advantages of using full suffix stripping
include implementation efficiency conveniences because there are <em>
fewer</em> unique reduced words than there are S-stemmed words.  The number
of different features to be analysed is therefore smaller, providing
both space and time advantages in an implementation.  This result was
verified by a few different sets of experiments.
<p>
The question posed by hypothesis<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node34.html#hngpsw">2</a> was answered partially
in [<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node40.html#Wyle91">Wyle91</a>], and new experiments lead to the same result:  In the
Pasadena test environment words are better indexing features for vector
space comparisons than overlapping N-grams.  However, as indicated in
[<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node40.html#Teuf89">Teuf89</a>], N-grams can be more efficient in their use of computing
resources.  There are usually fewer unique indexing features when
N-grams are used, and the performance difference between using words
and using N-grams is not as large as one might expect.  However,
messages within the Matrix have different characteristics from
the bibliographical citations in a small, static test collection.  In
[<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node40.html#Wyle89">Wyle89</a>], it was shown that more different N-grams appear in WAN
messages.  Part of the implementation efficiency advantage is therefore
no longer applicable.  The class of overlapping N-grams suggested by
Teufel involves <em> extending</em> smaller N-grams based on their
information theoretical noise in a collection.  In static collections,
these values can be calculated once and used repeatedly; but in dynamic
document collections, they must continually be re-computed.  This
re-computation therefore gives N-grams a system performance <em> penalty</em>
over using words.  Finally, words can be extended to phrases which turn
out to be much better indexing features than either N-grams or single
words.
<p>
Hypothesis<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node34.html#hind">3</a> can be answered clear and simply:  The indirect
similarity measure is better than the standard cosine measure.  The
performance improvement due to this RSV algorithm is also greater than
the difference due to indexing feature type.  The indirect similarity
RSV algorithm performs better than the cosine algorithm regardless of
which indexing features are used.  Unfortunately, the use of an
indirect similarity measure imposes a relatively large computing
resource performance penalty.  Through the use of incremental indexing
and inverted file indices, it is possible to trade storage space for
computation time  (see section<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node27.html#implementation">4.4</a>); yet any
implementation of the indirect comparison RSV function will require
significantly more computing resources than a direct measure.
Within the current Pasadena test environment, it <em> is</em> possible 
to use an indirect comparison function.  The resource penalty is
worth the retrieval performance improvements obtained.
<p>
The answer to hypothesis<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node34.html#hsph">4</a> is not as simple.  Although the
use of simple syntactic phrases [<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node40.html#Faga87">Faga87</a>] provides slightly better
retrieval performance, the performance difference is very small.  The
storage space required for the large number of additional indexing
features is very large, however.  In our test environment, subscribers
are encouraged to use large texts for queries.  Expanding the single
word features from these long natural language queries into phrases
using simple techniques leads to explosively many phrase features.
This large number of features in turn leads to a very significant
increase in the storage requirements for indexing and also to many more
feature comparisons during the RSV calculations.  We therefore support
Fagan's conclusion and recommend that this technique not be used for
retrieval in WAN message based systems.
<p>
However, hypothesis<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node34.html#hnph">5</a> can clearly be answered in the
affirmative.  The generation of phrase features by the symmetric
extension of single word features performed better than any other
features tested in the system.  The number of features generated by
this technique is relatively small, and the retrieval performance
improvements are significant.  This new phrase generation technique
(described in section<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node16.html#secstruc">2.3</a>) is perhaps one of the most
significant developments presented in this thesis.  The computing
resources required to implement this word extension technique are also
quite modest.
Hypothesis<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node34.html#hnph">5</a> is re-confirmed by the fact that the
performance improvement by the retrieval method using an indirect
similarity RSV function and noise extended phrases for indexing
features over one using simple phrases and the cosine RSV function is
the largest performance difference detected in all of the experiments.
Although the indirect similarity measure requires more computational
resources (processor cycles) than the cosine measure, the amount
of storage required for the simple phrase technique is prohibitively
large.
<p>
Verifying the results on static collections reported in [<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node40.html#Fre91b">Fre91b</a>],
the answer to hypothesis<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node34.html#hnorm">6</a> is also in the affirmative.  The
simple normalization technique for feature frequency within a query or
message does perform better than using only the feature frequency in
weighting functions within the our Matrix filtering environment.
The computational resource expense imposed by this normalization is
also small.  As reported in [<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node40.html#Fre91b">Fre91b</a>], the technique is especially
useful in a situation where messages of widely varying lengths are
being compared.  Since WAN messages do vary widely in length, this
technique is well-suited to our purpose.
<p>
Although the excerpt retrieval technique recently reported by Salton
and Buckley for use in a static, on-line encyclopedia [<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node40.html#Salt91">Salt91</a>]
does indeed perform better than the baseline single word feature cosine
technique in the Pasadena test bed, the answer to 
hypothesis <a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node34.html#hsps">7</a> is not a clear and simple ``yes.''  First of all, the
technique necessitates a storage performance penalty for keeping
excerpt frequency data.  This penalty is somewhat higher in Matrix
filtering systems like Pasadena which use an incremental indexing
strategy for WAN messages.  Secondly, the large number of individual
excerpt comparisons is computationally much more costly than individual
``global'' comparisons.  Finally, the performance improvement in the
Pasadena system is not large and the technique did not perform as well
as other methods developed specifically for WAN messages.  The method
would seem to be more appropriate for large, static lexicon searching
than for WAN message filtering.
<p>
The answer to the final hypotheses,<a href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node34.html#hipd">8</a>, is also positive, but
again qualified by computing resource requirement penalties.  The
inverse feature density term weighting function performs better than
other term weighting functions for WAN messages, but at the cost of
using more storage.  When using incremental indexing methods, such as
those in systems like Pasadena, feature frequencies within each WAN
paragraph type must be stored for each message.  This added storage is
a stiff price to pay for the marginally improved performance.  The added
storage requirements are comparable to those required in the excerpt
retrieval technique. Since performance improvements are marginal, it is
questionable whether this feature weighting function is worth the
increased storage.
<p>
The optimal combination of the retrieval algorithm
components tested in the Pasadena system is:
<ul><li> full Porter word stemming,
  <li> features composed of all individual words and 
        phrases generated by iteratively, symmetrically extending
        high-noise words,
  <li> normalized inverse feature density term weighting, and
  <li> the indirect RSV function.
</ul>
This combination was implemented in the <b> npi</b> algorithm and
provided the best retrieval performance of all algorithms tested.
<p>
In this section, we answered the questions formulated in the hypotheses
of the last chapter and discussed some of the computational requirements
needed for this improved performance.  In the next two sections, we offer
some comments about system evaluation in general and an assessment of
the Pasadena system in particular.
<p>
<br> <hr><a name="tex2html1526" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node37.html"><img align="BOTTOM" alt="next" src="https://web.archive.org/web/19971014211003im_/http://vhdl.org/~wyle/diss/images/next_motif.gif"></a>   <a name="tex2html1524" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node35.html"><img align="BOTTOM" alt="up" src="https://web.archive.org/web/19971014211003im_/http://vhdl.org/~wyle/diss/images/up_motif.gif"></a>   <a name="tex2html1518" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node35.html"><img align="BOTTOM" alt="previous" src="https://web.archive.org/web/19971014211003im_/http://vhdl.org/~wyle/diss/images/previous_motif.gif"></a>   <a name="tex2html1528" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node2.html"><img align="BOTTOM" alt="contents" src="https://web.archive.org/web/19971014211003im_/http://vhdl.org/~wyle/diss/images/contents_motif.gif"></a>   <a name="tex2html1529" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node57.html"><img align="BOTTOM" alt="index" src="https://web.archive.org/web/19971014211003im_/http://vhdl.org/~wyle/diss/images/index_motif.gif"></a>   <br>
<b> Next:</b> <a name="tex2html1527" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node37.html"> Performance Evaluation in </a>
<b>Up:</b> <a name="tex2html1525" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node35.html"> Conclusionand Outlook</a>
<b> Previous:</b> <a name="tex2html1519" href="https://web.archive.org/web/19971014211003/http://www.vhdl.org/~wyle/diss/node35.html"> Conclusionand Outlook</a>
<br> <hr> <p>
<br> <hr>
<p><address>
<i>Mitchell F. Wyle <br>
Wed Jan  3 13:22:21 EST 1996</i>
</address>
</body>
<!--
     FILE ARCHIVED ON 21:10:03 Oct 14, 1997 AND RETRIEVED FROM THE
     INTERNET ARCHIVE ON 17:12:15 Aug 04, 2022.
     JAVASCRIPT APPENDED BY WAYBACK MACHINE, COPYRIGHT INTERNET ARCHIVE.

     ALL OTHER CONTENT MAY ALSO BE PROTECTED BY COPYRIGHT (17 U.S.C.
     SECTION 108(a)(3)).
-->
<!--
playback timings (ms):
  captures_list: 451.814
  exclusion.robots: 0.094
  exclusion.robots.policy: 0.089
  cdx.remote: 0.04
  esindex: 0.004
  LoadShardBlock: 410.5 (3)
  PetaboxLoader3.resolve: 185.498 (3)
  PetaboxLoader3.datanode: 211.645 (4)
  CDXLines.iter: 12.204 (3)
  load_resource: 88.223
-->